{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "print(\"OK \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "# Make sure src/ is on the Python path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "from pdf_extraction import extract_pdf_text_smart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e44fdc",
   "metadata": {},
   "source": [
    "# Test Sample pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae670888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "pdf_path = PROJECT_ROOT / \"data\" / \"sample2.pdf\"   # digital test life(sample2)\n",
    "pdf_path, pdf_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549301fe",
   "metadata": {},
   "source": [
    "# Minimal PyMuPDF text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f40896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "doc = fitz.open(pdf_path)\n",
    "all_text = \"\"\n",
    "\n",
    "for page in doc:\n",
    "    page_text = page.get_text(\"text\")  # plain text mode\n",
    "    all_text += \"\\n\\n--- PAGE BREAK ---\\n\\n\"\n",
    "    all_text += page_text\n",
    "doc.close()\n",
    "print(all_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dba3f4",
   "metadata": {},
   "source": [
    "# Page-wise structured extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "doc = fitz.open(pdf_path)\n",
    "pages = []\n",
    "for page_number, page in enumerate(doc, start=1):\n",
    "    text = page.get_text(\"text\")\n",
    "    pages.append({\n",
    "        \"page_number\": page_number,\n",
    "        \"char_count\": len(text),\n",
    "        \"text\": text\n",
    "    })\n",
    "doc.close()\n",
    "len(pages), pages[0][\"page_number\"], pages[0][\"char_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4764e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to inspect on one page\n",
    "\n",
    "print(f\"Total pages: {len(pages)}\\n\")\n",
    "for p in pages:\n",
    "    print(f\"=== PAGE {p['page_number']} | chars: {p['char_count']} ===\")\n",
    "    print(p[\"text\"][:500])\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca743109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic: detect “probably scanned” pages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "char_counts = [p[\"char_count\"] for p in pages]\n",
    "print(\"Char counts per page:\", char_counts)\n",
    "\n",
    "avg_chars = np.mean(char_counts) if char_counts else 0\n",
    "print(\"Average chars per page:\", avg_chars)\n",
    "\n",
    "# Simple rule: pages with very few chars are suspicious (likely scanned)\n",
    "scanned_like_pages = [p for p in pages if p[\"char_count\"] < 50]\n",
    "print(\"Pages that look scanned (char_count < 50):\")\n",
    "[(p[\"page_number\"], p[\"char_count\"]) for p in scanned_like_pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125c7ba",
   "metadata": {},
   "source": [
    "# OCR helper (Not fully integrate yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80358dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "def ocr_single_page(pdf_path, page_number, dpi=300, lang=\"eng\"):\n",
    "    \"\"\"\n",
    "    OCR one page (1-based page_number) from the PDF.\n",
    "    Returns extracted text as string.\n",
    "    \"\"\"\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_number,\n",
    "        last_page=page_number,\n",
    "        dpi=dpi\n",
    "    )\n",
    "    if not images:\n",
    "        return \"\"\n",
    "    \n",
    "    img = images[0]\n",
    "    text = pytesseract.image_to_string(img, lang=lang)\n",
    "    return text\n",
    "\n",
    "# Example: OCR page 1\n",
    "ocr_text_page_1 = ocr_single_page(pdf_path, page_number=1)\n",
    "print(ocr_text_page_1[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b3a85",
   "metadata": {},
   "source": [
    "#  unified extractor function\n",
    "\n",
    "Return a structured dict we can reuse later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea31d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "def extract_pdf_text_smart(pdf_path, force_ocr=False, scanned_threshold=50, dpi=300, lang=\"eng\"):\n",
    "    \"\"\"\n",
    "    Smart PDF text extraction:\n",
    "    - Uses direct text extraction when possible\n",
    "    - Falls back to OCR for pages that look scanned or when force_ocr=True\n",
    "    Returns a dict with:\n",
    "      - file_name\n",
    "      - total_pages\n",
    "      - pages: list of {page_number, mode, char_count, text}\n",
    "      - full_text\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    pages_data = []\n",
    "    full_text_parts = []\n",
    "    \n",
    "    total_pages = len(doc)\n",
    "    \n",
    "    for page_index, page in enumerate(doc, start=1):\n",
    "        # 1) Try direct extraction\n",
    "        direct_text = page.get_text(\"text\")\n",
    "        direct_text = direct_text or \"\"\n",
    "        direct_char_count = len(direct_text)\n",
    "        \n",
    "        use_ocr = force_ocr or (direct_char_count < scanned_threshold)\n",
    "        \n",
    "        if use_ocr:\n",
    "            # 2) OCR fallback\n",
    "            images = convert_from_path(\n",
    "                pdf_path,\n",
    "                first_page=page_index,\n",
    "                last_page=page_index,\n",
    "                dpi=dpi\n",
    "            )\n",
    "            if images:\n",
    "                ocr_text = pytesseract.image_to_string(images[0], lang=lang)\n",
    "            else:\n",
    "                ocr_text = \"\"\n",
    "            \n",
    "            raw_text = ocr_text\n",
    "            mode = \"ocr\"\n",
    "        else:\n",
    "            raw_text = direct_text\n",
    "            mode = \"direct\"\n",
    "        \n",
    "        # 3) Clean text a bit\n",
    "        cleaned_text = clean_text_basic(raw_text)\n",
    "        \n",
    "        pages_data.append({\n",
    "            \"page_number\": page_index,\n",
    "            \"mode\": mode,               # \"direct\" or \"ocr\"\n",
    "            \"char_count\": len(cleaned_text),\n",
    "            \"text\": cleaned_text\n",
    "        })\n",
    "        \n",
    "        full_text_parts.append(f\"\\n\\n--- PAGE {page_index} ({mode}) ---\\n\\n\")\n",
    "        full_text_parts.append(cleaned_text)\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    full_text = \"\".join(full_text_parts)\n",
    "    \n",
    "    return {\n",
    "        \"file_name\": pdf_path.name if hasattr(pdf_path, \"name\") else str(pdf_path),\n",
    "        \"total_pages\": total_pages,\n",
    "        \"pages\": pages_data,\n",
    "        \"full_text\": full_text\n",
    "    }\n",
    "\n",
    "def clean_text_basic(text: str) -> str:\n",
    "    \"\"\"Simple text cleaning: collapse spaces/newlines, strip.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Collapse multiple whitespace to single space/newline combos\n",
    "    text = re.sub(r'\\r', '\\n', text)\n",
    "    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing unified extractor function\n",
    "result = extract_pdf_text_smart(pdf_path)\n",
    "\n",
    "print(\"File:\", result[\"file_name\"])\n",
    "print(\"Total pages:\", result[\"total_pages\"])\n",
    "for p in result[\"pages\"]:\n",
    "    print(f\"Page {p['page_number']}: mode={p['mode']}, chars={p['char_count']}\")\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "print(result[\"full_text\"][:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba39b1",
   "metadata": {},
   "source": [
    "# Testing on scanned image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_pdf_text_smart(r'C:\\Users\\KAMALESH MUKHERJEE\\Desktop\\Multimodal Medical Report Analyzer\\data\\sample_scanned_image.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c8ce1",
   "metadata": {},
   "source": [
    "# Testing Both pdf's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b158c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_digital = PROJECT_ROOT / \"data\" / \"sample2.pdf\"\n",
    "pdf_scanned = PROJECT_ROOT / \"data\" / \"sample_scanned_image.pdf\"\n",
    "\n",
    "res_digital = extract_pdf_text_smart(pdf_digital)\n",
    "res_scanned = extract_pdf_text_smart(pdf_scanned)\n",
    "\n",
    "print(\"DIGITAL:\")\n",
    "print(res_digital[\"file_name\"], res_digital[\"total_pages\"])\n",
    "for p in res_digital[\"pages\"]:\n",
    "    print(f\"  Page {p['page_number']}: mode={p['mode']}, chars={p['char_count']}\")\n",
    "\n",
    "print(\"\\nSCANNED:\")\n",
    "print(res_scanned[\"file_name\"], res_scanned[\"total_pages\"])\n",
    "for p in res_scanned[\"pages\"]:\n",
    "    print(f\"  Page {p['page_number']}: mode={p['mode']}, chars={p['char_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a3287",
   "metadata": {},
   "source": [
    "# Code is working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65513ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_scanned = r'C:\\Users\\KAMALESH MUKHERJEE\\Desktop\\Multimodal Medical Report Analyzer\\data\\scanned_medical_report.pdf'\n",
    "res_scanned = extract_pdf_text_smart(pdf_scanned)\n",
    "print(\"\\nSCANNED:\")\n",
    "print(res_scanned[\"file_name\"], res_scanned[\"total_pages\"])\n",
    "for p in res_scanned[\"pages\"]:\n",
    "    print(f\"  Page {p['page_number']}: mode={p['mode']}, chars={p['char_count']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
